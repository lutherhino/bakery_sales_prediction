{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fc002b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94631b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. DATEN LADEN UND VORBEREITEN\n",
    "# =============================================================================\n",
    "def load_and_prepare_data():\n",
    "    \"\"\"Lädt die Daten und bereitet sie für das Modelling vor.\"\"\"\n",
    "    print(\"Lade Daten...\")\n",
    "    \n",
    "    # Daten laden\n",
    "    df = pd.read_csv('/workspaces/bakery_sales_prediction/2_BaselineModel/data/data_clean.csv')\n",
    "    sample_sub = pd.read_csv('/workspaces/bakery_sales_prediction/2_BaselineModel/datasets/sample_submission.csv')\n",
    "    \n",
    "    # Datum konvertieren\n",
    "    df['Datum'] = pd.to_datetime(df['Datum'])\n",
    "    \n",
    "    # Zusätzliche Zeit-Features erstellen\n",
    "    df['Tag'] = df['Datum'].dt.day\n",
    "    df['Monat'] = df['Datum'].dt.month\n",
    "    df['Jahr'] = df['Datum'].dt.year\n",
    "    df['Wochentag'] = df['Datum'].dt.dayofweek  # 0=Montag, 6=Sonntag\n",
    "    \n",
    "    # Wetter-Features erweitern\n",
    "    # Wetter-Cluster erstellen\n",
    "    df['wetter_cluster'] = df['Wettercode'].apply(create_weather_clusters)\n",
    "    \n",
    "    # One-Hot-Encoding für Wetter-Cluster\n",
    "    wetter_dummies = pd.get_dummies(df['wetter_cluster'], prefix='Wetter')\n",
    "    df = pd.concat([df, wetter_dummies], axis=1)\n",
    "    \n",
    "    # Temperaturkategorien\n",
    "    df['Temperatur_Kategorie'] = pd.cut(df['Temperatur'], \n",
    "                                      bins=[-float('inf'), 10, 20, 25, float('inf')],\n",
    "                                      labels=['kalt', 'mild', 'warm', 'heiss'])\n",
    "    \n",
    "    # One-Hot-Encoding für Temperaturkategorien\n",
    "    temp_dummies = pd.get_dummies(df['Temperatur_Kategorie'], prefix='Temp')\n",
    "    df = pd.concat([df, temp_dummies], axis=1)\n",
    "    \n",
    "    # Temperaturänderung zum Vortag\n",
    "    df['Temperatur_Delta'] = df.groupby(['Jahr', 'Monat'])['Temperatur'].diff()\n",
    "    \n",
    "    # Zyklische Zeitfeatures\n",
    "    df['tag_sin'] = np.sin(2 * np.pi * df['Tag']/31)\n",
    "    df['tag_cos'] = np.cos(2 * np.pi * df['Tag']/31)\n",
    "    df['monat_sin'] = np.sin(2 * np.pi * df['Monat']/12)\n",
    "    df['monat_cos'] = np.cos(2 * np.pi * df['Monat']/12)\n",
    "    \n",
    "    # Jahreszeiten (meteorologisch)\n",
    "    df['Jahreszeit'] = df['Monat'].map({\n",
    "        12:0, 1:0, 2:0,  # Winter\n",
    "        3:1, 4:1, 5:1,   # Frühling\n",
    "        6:2, 7:2, 8:2,   # Sommer\n",
    "        9:3, 10:3, 11:3  # Herbst\n",
    "    })\n",
    "    \n",
    "    print(f\"Daten geladen: {len(df)} Datensätze von {df['Datum'].min()} bis {df['Datum'].max()}\")\n",
    "    print(f\"Sample Submission: {len(sample_sub)} Vorhersagen benötigt\")\n",
    "    \n",
    "    return df, sample_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91f36d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. DATEN AUFTEILEN\n",
    "# =============================================================================\n",
    "\n",
    "def split_data(df):\n",
    "    \"\"\"Teilt die Daten in Train/Validation/Test auf.\"\"\"\n",
    "    print(\"\\nTeile Daten auf...\")\n",
    "    \n",
    "    # Zeitbasierte Aufteilung\n",
    "    train = df[df['Datum'] < '2017-08-01'].copy()\n",
    "    validation = df[(df['Datum'] >= '2017-08-01') & (df['Datum'] < '2018-08-01')].copy()\n",
    "    \n",
    "    print(f\"Training: {len(train)} Datensätze ({train['Datum'].min()} - {train['Datum'].max()})\")\n",
    "    print(f\"Validation: {len(validation)} Datensätze ({validation['Datum'].min()} - {validation['Datum'].max()})\")\n",
    "    \n",
    "    return train, validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04e2d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. FEATURES DEFINIEREN\n",
    "# =============================================================================\n",
    "\n",
    "def get_features(df=None):\n",
    "    \"\"\"Definiert die Features für die Regression.\"\"\"\n",
    "    # Basis-Wetter-Features\n",
    "    weather_features = [\n",
    "        'Bewoelkung', 'Temperatur', 'Windgeschwindigkeit', 'Wettercode',\n",
    "        'Wettercode_fehlt', 'Temperatur_Delta'\n",
    "    ]\n",
    "    \n",
    "    # Temperatur-Kategorie Features\n",
    "    temp_features = [col for col in df.columns if col.startswith('Temp_')] if df is not None else [\n",
    "        'Temp_kalt', 'Temp_mild', 'Temp_warm', 'Temp_heiss'\n",
    "    ]\n",
    "    \n",
    "    # Wetter-Cluster Features\n",
    "    weather_cluster_features = [col for col in df.columns if col.startswith('Wetter_')] if df is not None else [\n",
    "        'Wetter_Bewölkung', 'Wetter_Sichtminderung', 'Wetter_Nebel',\n",
    "        'Wetter_Niederschlag', 'Wetter_Schauer', 'Wetter_Gewitter',\n",
    "        'Wetter_Extremwetter', 'Wetter_Fehlt'\n",
    "    ]\n",
    "    \n",
    "    # Feiertags-Features\n",
    "    holiday_features = [\n",
    "        'ist_feiertag', 'feiertag_vortag', 'feiertag_folgetag',\n",
    "        'KielerWoche'\n",
    "    ]\n",
    "    \n",
    "    # Zeit-Features\n",
    "    time_features = [\n",
    "        'Tag', 'Monat', 'Jahr', 'Wochentag',\n",
    "        'tag_sin', 'tag_cos', 'monat_sin', 'monat_cos',\n",
    "        'Jahreszeit'\n",
    "    ]\n",
    "    \n",
    "    # Alle Features kombinieren\n",
    "    features = (weather_features + temp_features + \n",
    "               weather_cluster_features + holiday_features + time_features)\n",
    "    \n",
    "    print(f\"Verwende {len(features)} Features: {features}\")\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5ca7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. WARENGRUPPEN IDENTIFIZIEREN\n",
    "# =============================================================================\n",
    "\n",
    "def get_product_groups(df):\n",
    "    \"\"\"Identifiziert aktive Warengruppen in den Daten.\"\"\"\n",
    "    product_columns = [col for col in df.columns if col.startswith('Warengruppe_')]\n",
    "    \n",
    "    active_groups = []\n",
    "    for col in product_columns:\n",
    "        if df[col].sum() > 0:  # Nur Warengruppen mit Daten\n",
    "            group_name = col.replace('Warengruppe_', '')\n",
    "            active_groups.append((group_name, col))\n",
    "    \n",
    "    print(f\"\\nAktive Warengruppen: {[group[0] for group in active_groups]}\")\n",
    "    return active_groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e3a6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. MODELL TRAINING\n",
    "# =============================================================================\n",
    "\n",
    "def train_models(train_data, validation_data, features, product_groups):\n",
    "    \"\"\"Trainiert separate Modelle für jede Warengruppe.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"MODELL TRAINING\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    models = {}\n",
    "    results = {}\n",
    "    imputers = {}\n",
    "    \n",
    "    for group_name, group_col in product_groups:\n",
    "        print(f\"\\nTrainiere Modell für {group_name}...\")\n",
    "        \n",
    "        # Daten für diese Warengruppe filtern\n",
    "        train_group = train_data[train_data[group_col] == 1].copy()\n",
    "        val_group = validation_data[validation_data[group_col] == 1].copy()\n",
    "        \n",
    "        if len(train_group) == 0:\n",
    "            print(f\"  Keine Trainingsdaten für {group_name}\")\n",
    "            continue\n",
    "            \n",
    "        # Features und Target vorbereiten\n",
    "        X_train = train_group[features]\n",
    "        y_train = train_group['Umsatz']\n",
    "        \n",
    "        # Imputer für fehlende Werte\n",
    "        imputer = SimpleImputer(strategy='median')\n",
    "        X_train_imputed = imputer.fit_transform(X_train)\n",
    "        \n",
    "        # Modell trainieren\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train_imputed, y_train)\n",
    "        \n",
    "        # Validierung\n",
    "        if len(val_group) > 0:\n",
    "            X_val = val_group[features]\n",
    "            X_val_imputed = imputer.transform(X_val)\n",
    "            y_val = val_group['Umsatz']\n",
    "            \n",
    "            y_pred = model.predict(X_val_imputed)\n",
    "            mae = mean_absolute_error(y_val, y_pred)\n",
    "            rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "            \n",
    "            results[group_name] = {\n",
    "                'mae': mae,\n",
    "                'rmse': rmse,\n",
    "                'train_samples': len(train_group),\n",
    "                'val_samples': len(val_group)\n",
    "            }\n",
    "            \n",
    "            print(f\"  Training: {len(train_group)} Datensätze\")\n",
    "            print(f\"  Validation: {len(val_group)} Datensätze\")\n",
    "            print(f\"  MAE: {mae:.2f}\")\n",
    "            print(f\"  RMSE: {rmse:.2f}\")\n",
    "        \n",
    "        models[group_name] = model\n",
    "        imputers[group_name] = imputer\n",
    "    \n",
    "    return models, results, imputers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121998c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. VORHERSAGEN ERSTELLEN\n",
    "# =============================================================================\n",
    "\n",
    "def create_predictions(models, imputers, sample_sub, features):\n",
    "    \"\"\"Erstellt Vorhersagen für das Test-Set.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"VORHERSAGEN ERSTELLEN\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Warengruppen-Mapping\n",
    "    group_mapping = {\n",
    "        '1': 'Brot',\n",
    "        '2': 'Brötchen', \n",
    "        '3': 'Croissant',\n",
    "        '4': 'Konditorei',\n",
    "        '5': 'Kuchen',\n",
    "        '6': 'Saisonbrot'\n",
    "    }\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    for idx, row in sample_sub.iterrows():\n",
    "        id_str = str(row['id'])\n",
    "        \n",
    "        # ID parsen: YYMMDD + Warengruppe\n",
    "        if len(id_str) == 7:\n",
    "            date_part = id_str[:6]  # YYMMDD\n",
    "            group_code = id_str[6]  # Warengruppe\n",
    "            \n",
    "            # Datum rekonstruieren\n",
    "            year = 2000 + int(date_part[:2])\n",
    "            month = int(date_part[2:4])\n",
    "            day = int(date_part[4:6])\n",
    "            \n",
    "            try:\n",
    "                date = datetime(year, month, day)\n",
    "                \n",
    "                # Features für Vorhersage erstellen\n",
    "                feature_dict = {\n",
    "                    'Tag': day,\n",
    "                    'Monat': month,\n",
    "                    'Jahr': year,\n",
    "                    'Wochentag': date.weekday(),\n",
    "                    # Zyklische Features\n",
    "                    'tag_sin': np.sin(2 * np.pi * day/31),\n",
    "                    'tag_cos': np.cos(2 * np.pi * day/31),\n",
    "                    'monat_sin': np.sin(2 * np.pi * month/12),\n",
    "                    'monat_cos': np.cos(2 * np.pi * month/12),\n",
    "                    # Jahreszeit\n",
    "                    'Jahreszeit': {12:0, 1:0, 2:0, 3:1, 4:1, 5:1, 6:2, 7:2, 8:2, 9:3, 10:3, 11:3}[month],\n",
    "                    # Dummy-Werte für Wetter und Feiertage (könnten verbessert werden)\n",
    "                    'Bewoelkung': 5.0,\n",
    "                    'Temperatur': 15.0,\n",
    "                    'Windgeschwindigkeit': 10.0,\n",
    "                    'Wettercode': 20.0,\n",
    "                    'Wettercode_fehlt': 0,\n",
    "                    'Temperatur_Delta': 0.0,  # Keine Änderung zum Vortag\n",
    "                    # Wetter-Cluster (Standard: bewölkt)\n",
    "                    'Wetter_Bewölkung': 1,\n",
    "                    'Wetter_Sichtminderung': 0,\n",
    "                    'Wetter_Nebel': 0,\n",
    "                    'Wetter_Niederschlag': 0,\n",
    "                    'Wetter_Schauer': 0,\n",
    "                    'Wetter_Gewitter': 0,\n",
    "                    'Wetter_Extremwetter': 0,\n",
    "                    'Wetter_Fehlt': 0,\n",
    "                    # One-Hot-Encoding für Temperatur (basierend auf 15°C = mild)\n",
    "                    'Temp_kalt': 0,\n",
    "                    'Temp_mild': 1,\n",
    "                    'Temp_warm': 0,\n",
    "                    'Temp_heiss': 0,\n",
    "                    'ist_feiertag': 0,\n",
    "                    'feiertag_vortag': 0,\n",
    "                    'feiertag_folgetag': 0,\n",
    "                    'KielerWoche': 0\n",
    "                }\n",
    "                \n",
    "                # Vorhersage mit entsprechendem Modell\n",
    "                group_name = group_mapping.get(group_code)\n",
    "                if group_name and group_name in models:\n",
    "                    X_pred = pd.DataFrame([feature_dict])[features]\n",
    "                    X_pred_imputed = imputers[group_name].transform(X_pred)\n",
    "                    prediction = models[group_name].predict(X_pred_imputed)[0]\n",
    "                    prediction = max(0, prediction)  # Keine negativen Umsätze\n",
    "                else:\n",
    "                    prediction = 0  # Fallback\n",
    "                \n",
    "                predictions.append(prediction)\n",
    "                \n",
    "            except ValueError:\n",
    "                predictions.append(0)  # Fallback bei ungültigem Datum\n",
    "        else:\n",
    "            predictions.append(0)  # Fallback bei ungültiger ID\n",
    "    \n",
    "    # Ergebnis-DataFrame erstellen\n",
    "    result_df = sample_sub.copy()\n",
    "    result_df['Umsatz'] = predictions\n",
    "    \n",
    "    print(f\"Vorhersagen erstellt für {len(predictions)} IDs\")\n",
    "    print(f\"Durchschnittlicher vorhergesagter Umsatz: {np.mean(predictions):.2f}\")\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c7d65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. HAUPTFUNKTION\n",
    "# =============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Hauptfunktion für die komplette Pipeline.\"\"\"\n",
    "    print(\"BÄCKEREI UMSATZ VORHERSAGE\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # 1. Daten laden\n",
    "    df, sample_sub = load_and_prepare_data()\n",
    "    \n",
    "    # 2. Daten aufteilen\n",
    "    train_data, validation_data = split_data(df)\n",
    "    \n",
    "    # 3. Features definieren\n",
    "    features = get_features(df)\n",
    "    \n",
    "    # 4. Warengruppen identifizieren\n",
    "    product_groups = get_product_groups(df)\n",
    "    \n",
    "    # 5. Modelle trainieren\n",
    "    models, results, imputers = train_models(train_data, validation_data, features, product_groups)\n",
    "    \n",
    "    # 6. Vorhersagen erstellen\n",
    "    predictions_df = create_predictions(models, imputers, sample_sub, features)\n",
    "    \n",
    "    # 7. Ergebnisse speichern\n",
    "    output_path = '/workspaces/bakery_sales_prediction/2_BaselineModel/predictions_linear_regression.csv'\n",
    "    predictions_df.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*50)\n",
    "    print(\"FERTIG!\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Vorhersagen gespeichert in: {output_path}\")\n",
    "    \n",
    "    # Zusammenfassung der Modell-Performance\n",
    "    if results:\n",
    "        print(\"\\nModell-Performance (Validation):\")\n",
    "        for group, metrics in results.items():\n",
    "            print(f\"  {group}: MAE={metrics['mae']:.2f}, RMSE={metrics['rmse']:.2f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# AUSFÜHRUNG\n",
    "# =============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
