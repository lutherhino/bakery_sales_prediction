{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2560686",
   "metadata": {},
   "source": [
    "# ğŸ¥– Backwaren-Preisdaten Integration\n",
    "\n",
    "## ğŸ¯ Ziel\n",
    "Integration der Backwaren-Preisdaten aus `Preisentwicklung_Backwaren.csv` in `data_clean.csv`\n",
    "\n",
    "## ğŸ“‹ Workflow in BlÃ¶cken\n",
    "1. **Setup & Imports** - Bibliotheken laden\n",
    "2. **Daten laden** - Beide CSV-Dateien einlesen\n",
    "3. **Datenverarbeitung** - Preisdaten aufbereiten und mergen\n",
    "4. **Export** - Als neue CSV-Datei speichern\n",
    "5. **Validierung** - QualitÃ¤tskontrolle\n",
    "\n",
    "## ğŸ“ Dateien\n",
    "- **Input**: `data_clean.csv` (Hauptdaten)\n",
    "- **Input**: `Preisentwicklung_Backwaren.csv` (Preisdaten)\n",
    "- **Output**: `data_clean_with_bakery_prices.csv` (Ergebnis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34075613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ BLOCK 1: Setup & Imports\n",
      "==================================================\n",
      "âœ… Bibliotheken geladen\n",
      "ğŸ“… Aktuelles Datum: 2025-06-24 16:17\n",
      "ğŸ“ Arbeitsverzeichnis: /workspaces/bakery_sales_prediction/2_BaselineModel/data\n",
      "âœ… Block 1 abgeschlossen\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“¦ BLOCK 1: SETUP & IMPORTS\n",
    "print(\"ğŸ“¦ BLOCK 1: Setup & Imports\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"âœ… Bibliotheken geladen\")\n",
    "print(\"ğŸ“… Aktuelles Datum:\", datetime.now().strftime(\"%Y-%m-%d %H:%M\"))\n",
    "print(\"ğŸ“ Arbeitsverzeichnis:\", os.getcwd())\n",
    "print(\"âœ… Block 1 abgeschlossen\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71bb36bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ˆ BLOCK 2: Daten laden und analysieren\n",
      "==================================================\n",
      "ğŸ“Š Lade Hauptdaten...\n",
      "âœ… Hauptdaten geladen: 9,334 Zeilen, 46 Spalten\n",
      "ğŸ¥– Lade Backwaren-Preisdaten...\n",
      "âœ… Preisdaten geladen: 252 Zeilen, 5 Spalten\n",
      "\n",
      "ğŸ” Analyse der Hauptdaten:\n",
      "Datumsspalte: object\n",
      "Datumsbereich: 2013-07-01 bis 2018-07-31\n",
      "\n",
      "ğŸ” Analyse der Backwaren-Preisdaten:\n",
      "VerfÃ¼gbare Spalten: ['time', '1_variable_attribute_code', '1_variable_attribute_label', 'value', 'value_unit']\n",
      "Erste 5 Zeilen der Preisdaten:\n",
      "   time 1_variable_attribute_code 1_variable_attribute_label value value_unit\n",
      "0  2013                   MONAT01                     Januar  91,6   2020=100\n",
      "1  2013                   MONAT01                     Januar    88   2020=100\n",
      "2  2013                   MONAT01                     Januar  88,8   2020=100\n",
      "3  2013                   MONAT02                    Februar  91,9   2020=100\n",
      "4  2013                   MONAT02                    Februar    88   2020=100\n",
      "\n",
      "âœ… Block 2 abgeschlossen\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“ˆ BLOCK 2: DATEN LADEN UND ANALYSIEREN\n",
    "print(\"ğŸ“ˆ BLOCK 2: Daten laden und analysieren\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Hauptdaten laden\n",
    "print(\"ğŸ“Š Lade Hauptdaten...\")\n",
    "df_main = pd.read_csv('data_clean.csv')\n",
    "print(f\"âœ… Hauptdaten geladen: {df_main.shape[0]:,} Zeilen, {df_main.shape[1]} Spalten\")\n",
    "\n",
    "# Backwaren-Preisdaten laden\n",
    "print(\"ğŸ¥– Lade Backwaren-Preisdaten...\")\n",
    "df_bakery = pd.read_csv('Preisentwicklung_Backwaren.csv', sep=';')\n",
    "print(f\"âœ… Preisdaten geladen: {df_bakery.shape[0]:,} Zeilen, {df_bakery.shape[1]} Spalten\")\n",
    "\n",
    "# Datenstrukturen analysieren\n",
    "print(\"\\nğŸ” Analyse der Hauptdaten:\")\n",
    "print(f\"Datumsspalte: {df_main['Datum'].dtype}\")\n",
    "print(f\"Datumsbereich: {df_main['Datum'].min()} bis {df_main['Datum'].max()}\")\n",
    "\n",
    "print(\"\\nğŸ” Analyse der Backwaren-Preisdaten:\")\n",
    "print(\"VerfÃ¼gbare Spalten:\", df_bakery.columns.tolist())\n",
    "print(\"Erste 5 Zeilen der Preisdaten:\")\n",
    "print(df_bakery.head())\n",
    "\n",
    "print(\"\\nâœ… Block 2 abgeschlossen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf7492f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš™ï¸ BLOCK 3: Datenverarbeitung\n",
      "==================================================\n",
      "ğŸ¥– Verwende bereits geladene Backwaren-Preisdaten...\n",
      "âœ… Preisdaten verfÃ¼gbar: 252 Zeilen\n",
      "ğŸ” Verwende alle verfÃ¼gbaren Preisdaten...\n",
      "âœ… Alle Daten: 252 EintrÃ¤ge\n",
      "ğŸ“… Bereite Zeitstempel auf...\n",
      "âœ… Preisdaten aufbereitet: 84 Jahr-Monat-Kombinationen\n",
      "ğŸ“Š Zeitraum Preisdaten: 2013-2019\n",
      "ğŸ“Š Bereite Hauptdaten vor...\n",
      "ğŸ“… Zeitraum Hauptdaten: 2013-2018\n",
      "ğŸ”— FÃ¼hre Merge durch...\n",
      "âœ… Nach Merge: 9334 Zeilen\n",
      "ğŸ“ˆ Forward Fill fÃ¼r fehlende Preisdaten...\n",
      "ğŸ“Š Fehlende Werte: 0 â†’ 0\n",
      "âœ… Finale Daten: 9334 Zeilen, 46 Spalten\n",
      "ğŸ“ˆ Neue Spalte hinzugefÃ¼gt: VPI_Backwaren\n",
      "ğŸ“Š VPI_Backwaren Statistik:\n",
      "   Min: 90.33\n",
      "   Max: 96.83\n",
      "   Median: 92.63\n",
      "\n",
      "âœ… Block 3 abgeschlossen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6543/1219488465.py:63: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_merged['VPI_Backwaren'] = df_merged['VPI_Backwaren'].fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "# âš™ï¸ BLOCK 3: DATENVERARBEITUNG - PREISDATEN INTEGRIEREN\n",
    "print(\"âš™ï¸ BLOCK 3: Datenverarbeitung\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 1. Backwaren-Preisdaten bereits in Block 2 geladen als df_bakery\n",
    "print(\"ğŸ¥– Verwende bereits geladene Backwaren-Preisdaten...\")\n",
    "print(f\"âœ… Preisdaten verfÃ¼gbar: {df_bakery.shape[0]:,} Zeilen\")\n",
    "\n",
    "# 2. Alle Preisdaten verwenden (da nur eine Kategorie vorhanden)\n",
    "print(\"ğŸ” Verwende alle verfÃ¼gbaren Preisdaten...\")\n",
    "bakery_clean = df_bakery.copy()\n",
    "print(f\"âœ… Alle Daten: {len(bakery_clean)} EintrÃ¤ge\")\n",
    "\n",
    "# 3. Zeitstempel und Werte aufbereiten\n",
    "print(\"ğŸ“… Bereite Zeitstempel auf...\")\n",
    "\n",
    "# Monat-Mapping\n",
    "month_map = {f'MONAT{i:02d}': i for i in range(1, 13)}\n",
    "\n",
    "# Zeitstempel erstellen\n",
    "bakery_clean['Jahr'] = bakery_clean['time']\n",
    "bakery_clean['Monat'] = bakery_clean['1_variable_attribute_code'].map(month_map)\n",
    "\n",
    "# Value-Spalte bereinigen (Komma zu Punkt)\n",
    "bakery_clean['VPI_Backwaren'] = pd.to_numeric(\n",
    "    bakery_clean['value'].astype(str).str.replace(',', '.'), \n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "# Nur relevante Spalten behalten und nach Jahr/Monat aggregieren (Mittelwert bei mehreren Werten pro Monat)\n",
    "price_data = bakery_clean[['Jahr', 'Monat', 'VPI_Backwaren']].dropna()\n",
    "price_data = price_data.groupby(['Jahr', 'Monat'])['VPI_Backwaren'].mean().reset_index()\n",
    "price_data = price_data.sort_values(['Jahr', 'Monat']).reset_index(drop=True)\n",
    "\n",
    "print(f\"âœ… Preisdaten aufbereitet: {len(price_data)} Jahr-Monat-Kombinationen\")\n",
    "print(f\"ğŸ“Š Zeitraum Preisdaten: {price_data['Jahr'].min():.0f}-{price_data['Jahr'].max():.0f}\")\n",
    "\n",
    "# 4. Hauptdaten vorbereiten\n",
    "print(\"ğŸ“Š Bereite Hauptdaten vor...\")\n",
    "df_main['Datum'] = pd.to_datetime(df_main['Datum'])\n",
    "df_main['Jahr'] = df_main['Datum'].dt.year\n",
    "df_main['Monat'] = df_main['Datum'].dt.month\n",
    "\n",
    "# Zeitraum der Hauptdaten\n",
    "main_start = df_main['Jahr'].min()\n",
    "main_end = df_main['Jahr'].max()\n",
    "print(f\"ğŸ“… Zeitraum Hauptdaten: {main_start}-{main_end}\")\n",
    "\n",
    "# 5. Merge durchfÃ¼hren\n",
    "print(\"ğŸ”— FÃ¼hre Merge durch...\")\n",
    "df_merged = pd.merge(\n",
    "    df_main, \n",
    "    price_data, \n",
    "    on=['Jahr', 'Monat'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"âœ… Nach Merge: {len(df_merged)} Zeilen\")\n",
    "\n",
    "# 6. Forward Fill fÃ¼r fehlende Werte\n",
    "print(\"ğŸ“ˆ Forward Fill fÃ¼r fehlende Preisdaten...\")\n",
    "missing_before = df_merged['VPI_Backwaren'].isnull().sum()\n",
    "df_merged['VPI_Backwaren'] = df_merged['VPI_Backwaren'].fillna(method='ffill')\n",
    "missing_after = df_merged['VPI_Backwaren'].isnull().sum()\n",
    "\n",
    "print(f\"ğŸ“Š Fehlende Werte: {missing_before} â†’ {missing_after}\")\n",
    "\n",
    "# 7. Daten auÃŸerhalb des Preis-Zeitraums anzeigen\n",
    "price_start = price_data['Jahr'].min()\n",
    "price_end = price_data['Jahr'].max()\n",
    "\n",
    "if price_start > main_start or price_end < main_end:\n",
    "    print(f\"âš ï¸ Zeitraum-Unterschied erkannt:\")\n",
    "    print(f\"   Preisdaten: {price_start:.0f}-{price_end:.0f}\")\n",
    "    print(f\"   Hauptdaten: {main_start}-{main_end}\")\n",
    "\n",
    "# 8. TemporÃ¤re Spalten entfernen\n",
    "df_final = df_merged.drop(columns=['Jahr', 'Monat'])\n",
    "\n",
    "print(f\"âœ… Finale Daten: {len(df_final)} Zeilen, {len(df_final.columns)} Spalten\")\n",
    "print(f\"ğŸ“ˆ Neue Spalte hinzugefÃ¼gt: VPI_Backwaren\")\n",
    "\n",
    "# Kurze Statistik der neuen Spalte\n",
    "if 'VPI_Backwaren' in df_final.columns:\n",
    "    vpi_stats = df_final['VPI_Backwaren'].describe()\n",
    "    print(f\"ğŸ“Š VPI_Backwaren Statistik:\")\n",
    "    print(f\"   Min: {vpi_stats['min']:.2f}\")\n",
    "    print(f\"   Max: {vpi_stats['max']:.2f}\")\n",
    "    print(f\"   Median: {vpi_stats['50%']:.2f}\")\n",
    "\n",
    "print(\"\\nâœ… Block 3 abgeschlossen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df80d8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ—‘ï¸ BLOCK 4: Datenbereinigung\n",
      "==================================================\n",
      "ğŸ” PrÃ¼fe vorhandene Feiertags-Spalten...\n",
      "ğŸ“Š Spalten vor Bereinigung: 46\n",
      "âœ… Gefundene Spalten zum Entfernen: 5\n",
      "   â€¢ Feiertag_Ostern\n",
      "   â€¢ Feiertag_Pfingsten\n",
      "   â€¢ Feiertag_Pfingstmontag\n",
      "   â€¢ Feiertag_Silvester\n",
      "   â€¢ Feiertag_Tag der Arbeit\n",
      "ğŸ—‘ï¸ 5 Feiertags-Spalten entfernt\n",
      "âš ï¸ Nicht gefundene Spalten: 1\n",
      "   â€¢ Feiertag_Ostermontag\n",
      "ğŸ“Š Spalten nach Bereinigung: 41\n",
      "ğŸ“‰ Reduzierung: 5 Spalten entfernt\n",
      "\n",
      "âœ… Block 4 abgeschlossen\n"
     ]
    }
   ],
   "source": [
    "# ğŸ—‘ï¸ BLOCK 4: DATENBEREINIGUNG - FEIERTAGS-SPALTEN ENTFERNEN\n",
    "print(\"ğŸ—‘ï¸ BLOCK 4: Datenbereinigung\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Liste der zu entfernenden Feiertags-Spalten\n",
    "columns_to_remove = [\n",
    "    'Feiertag_Ostermontag',\n",
    "    'Feiertag_Ostern', \n",
    "    'Feiertag_Pfingsten',\n",
    "    'Feiertag_Pfingstmontag',\n",
    "    'Feiertag_Silvester',\n",
    "    'Feiertag_Tag der Arbeit'\n",
    "]\n",
    "\n",
    "print(\"ğŸ” PrÃ¼fe vorhandene Feiertags-Spalten...\")\n",
    "print(f\"ğŸ“Š Spalten vor Bereinigung: {len(df_final.columns)}\")\n",
    "\n",
    "# PrÃ¼fen welche Spalten tatsÃ¤chlich vorhanden sind\n",
    "existing_columns = [col for col in columns_to_remove if col in df_final.columns]\n",
    "missing_columns = [col for col in columns_to_remove if col not in df_final.columns]\n",
    "\n",
    "if existing_columns:\n",
    "    print(f\"âœ… Gefundene Spalten zum Entfernen: {len(existing_columns)}\")\n",
    "    for col in existing_columns:\n",
    "        print(f\"   â€¢ {col}\")\n",
    "    \n",
    "    # Spalten entfernen\n",
    "    df_final = df_final.drop(columns=existing_columns)\n",
    "    print(f\"ğŸ—‘ï¸ {len(existing_columns)} Feiertags-Spalten entfernt\")\n",
    "else:\n",
    "    print(\"â„¹ï¸ Keine der angegebenen Feiertags-Spalten gefunden\")\n",
    "\n",
    "if missing_columns:\n",
    "    print(f\"âš ï¸ Nicht gefundene Spalten: {len(missing_columns)}\")\n",
    "    for col in missing_columns:\n",
    "        print(f\"   â€¢ {col}\")\n",
    "\n",
    "print(f\"ğŸ“Š Spalten nach Bereinigung: {len(df_final.columns)}\")\n",
    "print(f\"ğŸ“‰ Reduzierung: {len(existing_columns)} Spalten entfernt\")\n",
    "\n",
    "print(\"\\nâœ… Block 4 abgeschlossen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e87cdda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŒ¦ï¸ BLOCK 4.5: Wettercode-Bereinigung\n",
      "==================================================\n",
      "ğŸ” Gefundene Wettercode-Spalten: 2\n",
      "   â€¢ Wettercode\n",
      "   â€¢ Wettercode_fehlt\n",
      "\n",
      "ğŸ“Š Verarbeite Spalte: Wettercode\n",
      "   â€¢ Werte '99': 2325 (24.9%)\n",
      "   â€¢ GÃ¼ltige Werte: 7009\n",
      "   ğŸ”§ FÃ¼hre k-nearest Imputation durch...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… Imputation abgeschlossen\n",
      "   â€¢ Verbleibende NaN: 0\n",
      "   â€¢ Eindeutige Werte nach Imputation: [np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9)]...\n",
      "\n",
      "ğŸ“Š Verarbeite Spalte: Wettercode_fehlt\n",
      "   â€¢ Werte '99': 0 (0.0%)\n",
      "   â€¢ GÃ¼ltige Werte: 9334\n",
      "   âœ… Keine '99'-Werte gefunden\n",
      "\n",
      "ğŸ“‹ Zusammenfassung Wettercode-Bereinigung:\n",
      "   â€¢ Verarbeitete Spalten: 2\n",
      "   â€¢ Methode: k-nearest neighbors (k=5)\n",
      "   â€¢ Fallback: Forward/Backward Fill\n",
      "\n",
      "âœ… Block 4.5 abgeschlossen\n"
     ]
    }
   ],
   "source": [
    "# ğŸŒ¦ï¸ BLOCK 4.5: WETTERCODE-BEREINIGUNG MIT K-NEAREST IMPUTATION\n",
    "print(\"ğŸŒ¦ï¸ BLOCK 4.5: Wettercode-Bereinigung\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Wettercode-Spalten identifizieren\n",
    "weather_cols = [col for col in df_final.columns if 'wettercode' in col.lower() or 'weather' in col.lower()]\n",
    "print(f\"ğŸ” Gefundene Wettercode-Spalten: {len(weather_cols)}\")\n",
    "for col in weather_cols:\n",
    "    print(f\"   â€¢ {col}\")\n",
    "\n",
    "if weather_cols:\n",
    "    for col in weather_cols:\n",
    "        print(f\"\\nğŸ“Š Verarbeite Spalte: {col}\")\n",
    "        \n",
    "        # Anzahl der \"99\"-Werte prÃ¼fen\n",
    "        count_99 = (df_final[col] == 99).sum()\n",
    "        total_values = len(df_final[col])\n",
    "        percentage_99 = (count_99 / total_values) * 100\n",
    "        \n",
    "        print(f\"   â€¢ Werte '99': {count_99} ({percentage_99:.1f}%)\")\n",
    "        print(f\"   â€¢ GÃ¼ltige Werte: {total_values - count_99}\")\n",
    "        \n",
    "        if count_99 > 0:\n",
    "            # \"99\"-Werte als NaN markieren\n",
    "            df_final[col] = df_final[col].replace(99, np.nan)\n",
    "            \n",
    "            # Bereite Features fÃ¼r KNN-Imputation vor\n",
    "            # Verwende numerische Spalten als Features (ohne Datum und Target)\n",
    "            feature_cols = df_final.select_dtypes(include=[np.number]).columns.tolist()\n",
    "            feature_cols = [c for c in feature_cols if c != col]  # Target-Spalte ausschlieÃŸen\n",
    "            \n",
    "            # Erstelle DataFrame fÃ¼r Imputation\n",
    "            impute_data = df_final[[col] + feature_cols].copy()\n",
    "            \n",
    "            # KNN-Imputation durchfÃ¼hren\n",
    "            print(f\"   ğŸ”§ FÃ¼hre k-nearest Imputation durch...\")\n",
    "            knn_imputer = KNNImputer(n_neighbors=5, weights='uniform')\n",
    "            \n",
    "            try:\n",
    "                # Imputation anwenden\n",
    "                imputed_values = knn_imputer.fit_transform(impute_data)\n",
    "                \n",
    "                # Nur die Target-Spalte zurÃ¼ckschreiben\n",
    "                df_final[col] = imputed_values[:, 0]\n",
    "                \n",
    "                # Auf ganze Zahlen runden (da Wettercode diskret ist)\n",
    "                df_final[col] = np.round(df_final[col]).astype(int)\n",
    "                \n",
    "                # Validierung nach Imputation\n",
    "                remaining_nan = df_final[col].isnull().sum()\n",
    "                print(f\"   âœ… Imputation abgeschlossen\")\n",
    "                print(f\"   â€¢ Verbleibende NaN: {remaining_nan}\")\n",
    "                \n",
    "                # Werteverteilung nach Imputation\n",
    "                unique_values = sorted(df_final[col].unique())\n",
    "                print(f\"   â€¢ Eindeutige Werte nach Imputation: {unique_values[:10]}...\")  # Erste 10 zeigen\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   âŒ Fehler bei Imputation: {e}\")\n",
    "                print(f\"   ğŸ”„ Verwende Forward-Fill als Fallback...\")\n",
    "                df_final[col] = df_final[col].fillna(method='ffill').fillna(method='bfill')\n",
    "        else:\n",
    "            print(f\"   âœ… Keine '99'-Werte gefunden\")\n",
    "else:\n",
    "    print(\"â„¹ï¸ Keine Wettercode-Spalten gefunden\")\n",
    "    # Suche nach anderen mÃ¶glichen Wetterspalten\n",
    "    potential_weather = [col for col in df_final.columns if any(word in col.lower() for word in ['temp', 'rain', 'wind', 'humid', 'press'])]\n",
    "    if potential_weather:\n",
    "        print(f\"ğŸ’¡ MÃ¶gliche Wetter-Spalten gefunden: {potential_weather}\")\n",
    "\n",
    "# Zusammenfassung\n",
    "print(f\"\\nğŸ“‹ Zusammenfassung Wettercode-Bereinigung:\")\n",
    "print(f\"   â€¢ Verarbeitete Spalten: {len(weather_cols)}\")\n",
    "print(f\"   â€¢ Methode: k-nearest neighbors (k=5)\")\n",
    "print(f\"   â€¢ Fallback: Forward/Backward Fill\")\n",
    "\n",
    "print(\"\\nâœ… Block 4.5 abgeschlossen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52b8cd2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ BLOCK 5: Export\n",
      "==================================================\n",
      "ğŸ“ Speichere finale Daten als: data_clean_with_bakery_sales.csv\n",
      "âœ… Export erfolgreich!\n",
      "ğŸ“Š Finale Datei-Statistiken:\n",
      "   â€¢ Dateiname: data_clean_with_bakery_sales.csv\n",
      "   â€¢ DateigrÃ¶ÃŸe: 1,271,464 Bytes (1.21 MB)\n",
      "   â€¢ Zeilen: 9,334\n",
      "   â€¢ Spalten: 41\n",
      "\n",
      "ğŸ“‹ Spalten in der finalen Datei:\n",
      "    1. ğŸ“Š id\n",
      "    2. ğŸ“Š Datum\n",
      "    3. ğŸ“Š Umsatz\n",
      "    4. ğŸ“Š KielerWoche\n",
      "    5. ğŸ“Š Bewoelkung\n",
      "    6. ğŸ“Š Temperatur\n",
      "    7. ğŸ“Š Windgeschwindigkeit\n",
      "    8. ğŸ“Š Wettercode\n",
      "    9. ğŸ“Š ist_feiertag\n",
      "   10. ğŸ“Š feiertag_vortag\n",
      "   11. ğŸ“Š feiertag_folgetag\n",
      "   12. ğŸ“Š Wettercode_fehlt\n",
      "   13. ğŸ“Š Warengruppe_Brot\n",
      "   14. ğŸ“Š Warengruppe_BrÃ¶tchen\n",
      "   15. ğŸ“Š Warengruppe_Croissant\n",
      "   16. ğŸ“Š Warengruppe_Konditorei\n",
      "   17. ğŸ“Š Warengruppe_Kuchen\n",
      "   18. ğŸ“Š Warengruppe_Saisonbrot\n",
      "   19. ğŸ“Š Wochentag_Monday\n",
      "   20. ğŸ“Š Wochentag_Saturday\n",
      "   21. ğŸ“Š Wochentag_Sunday\n",
      "   22. ğŸ“Š Wochentag_Thursday\n",
      "   23. ğŸ“Š Wochentag_Tuesday\n",
      "   24. ğŸ“Š Wochentag_Wednesday\n",
      "   25. ğŸ“Š Monat_2\n",
      "   26. ğŸ“Š Monat_3\n",
      "   27. ğŸ“Š Monat_4\n",
      "   28. ğŸ“Š Monat_5\n",
      "   29. ğŸ“Š Monat_6\n",
      "   30. ğŸ“Š Monat_7\n",
      "   31. ğŸ“Š Monat_8\n",
      "   32. ğŸ“Š Monat_9\n",
      "   33. ğŸ“Š Monat_10\n",
      "   34. ğŸ“Š Monat_11\n",
      "   35. ğŸ“Š Monat_12\n",
      "   36. ğŸ“Š Jahreszeit_Herbst\n",
      "   37. ğŸ“Š Jahreszeit_Sommer\n",
      "   38. ğŸ“Š Jahreszeit_Winter\n",
      "   39. ğŸ“Š Feiertag_Heiligabend\n",
      "   40. ğŸ“Š Feiertag_Kein_Feiertag\n",
      "   41. ğŸ†• VPI_Backwaren\n",
      "\n",
      "ğŸ‘€ Datenvorschau (erste 3 Zeilen):\n",
      "     Datum     Umsatz  VPI_Backwaren\n",
      "2013-07-01 148.828353      90.933333\n",
      "2013-07-01 201.198426      90.933333\n",
      "2013-07-01 317.475875      90.933333\n",
      "\n",
      "ğŸ“… Zeitraum der finalen Daten:\n",
      "   â€¢ Von: 2013-07-01 00:00:00\n",
      "   â€¢ Bis: 2018-07-31 00:00:00\n",
      "   â€¢ Tage: 9334 DatensÃ¤tze\n",
      "\n",
      "âœ… Block 5 abgeschlossen\n",
      "\n",
      "ğŸ‰ GESAMTER WORKFLOW ABGESCHLOSSEN!\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# ğŸ’¾ BLOCK 5: EXPORT - FINALE DATEN SPEICHERN\n",
    "print(\"ğŸ’¾ BLOCK 5: Export\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Dateiname fÃ¼r Export definieren\n",
    "output_filename = 'data_clean_with_bakery_sales.csv'\n",
    "\n",
    "print(f\"ğŸ“ Speichere finale Daten als: {output_filename}\")\n",
    "\n",
    "try:\n",
    "    # CSV-Export durchfÃ¼hren\n",
    "    df_final.to_csv(output_filename, index=False)\n",
    "    \n",
    "    # DateigrÃ¶ÃŸe prÃ¼fen\n",
    "    file_size = os.path.getsize(output_filename)\n",
    "    file_size_mb = file_size / (1024 * 1024)\n",
    "    \n",
    "    print(f\"âœ… Export erfolgreich!\")\n",
    "    print(f\"ğŸ“Š Finale Datei-Statistiken:\")\n",
    "    print(f\"   â€¢ Dateiname: {output_filename}\")\n",
    "    print(f\"   â€¢ DateigrÃ¶ÃŸe: {file_size:,} Bytes ({file_size_mb:.2f} MB)\")\n",
    "    print(f\"   â€¢ Zeilen: {len(df_final):,}\")\n",
    "    print(f\"   â€¢ Spalten: {len(df_final.columns)}\")\n",
    "    \n",
    "    # Spalten-Ãœbersicht\n",
    "    print(f\"\\nğŸ“‹ Spalten in der finalen Datei:\")\n",
    "    for i, col in enumerate(df_final.columns, 1):\n",
    "        marker = \"ğŸ†•\" if col == \"VPI_Backwaren\" else \"ğŸ“Š\"\n",
    "        print(f\"   {i:2d}. {marker} {col}\")\n",
    "    \n",
    "    # Datenvorschau\n",
    "    print(f\"\\nğŸ‘€ Datenvorschau (erste 3 Zeilen):\")\n",
    "    preview_cols = ['Datum', 'Umsatz', 'VPI_Backwaren'] if 'VPI_Backwaren' in df_final.columns else ['Datum', 'Umsatz']\n",
    "    available_preview_cols = [col for col in preview_cols if col in df_final.columns]\n",
    "    \n",
    "    if available_preview_cols:\n",
    "        print(df_final[available_preview_cols].head(3).to_string(index=False))\n",
    "    \n",
    "    # Zeitraum-Info\n",
    "    if 'Datum' in df_final.columns:\n",
    "        print(f\"\\nğŸ“… Zeitraum der finalen Daten:\")\n",
    "        print(f\"   â€¢ Von: {df_final['Datum'].min()}\")\n",
    "        print(f\"   â€¢ Bis: {df_final['Datum'].max()}\")\n",
    "        print(f\"   â€¢ Tage: {len(df_final)} DatensÃ¤tze\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Fehler beim Export: {e}\")\n",
    "    print(\"ğŸ’¡ MÃ¶gliche LÃ¶sungen:\")\n",
    "    print(\"   â€¢ Schreibrechte im Ordner prÃ¼fen\")\n",
    "    print(\"   â€¢ Ausreichend Speicherplatz verfÃ¼gbar?\")\n",
    "    print(\"   â€¢ Datei bereits geÃ¶ffnet in Excel?\")\n",
    "\n",
    "print(\"\\nâœ… Block 5 abgeschlossen\")\n",
    "print(\"\\nğŸ‰ GESAMTER WORKFLOW ABGESCHLOSSEN!\")\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
