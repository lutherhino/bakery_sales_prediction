{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d08e43e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Naive Forecast: Umsatz vom letzten gleichen Wochentag\n",
      "============================================================\n",
      "üìã Lade Trainingsdaten...\n",
      "Datensatz geladen: 9334 Zeilen von 2013-07-01 00:00:00 bis 2018-07-31 00:00:00\n",
      "Warengruppen: ['Brot', 'Br√∂tchen', 'Croissant', 'Konditorei', 'Kuchen', 'Saisonbrot']\n",
      "Spalten: ['Datum', 'Jahr', 'Monat', 'Tag', 'Wochentag', 'Wochentag_Nr', 'Warengruppe', 'Warengruppe_Name', 'Temperatur', 'Windgeschwindigkeit', 'Bewoelkung', 'Wettercode_fehlt', 'ist_feiertag', 'Jahreszeit', 'ist_kiwo', 'Umsatz', 'Warengruppe_Brot', 'Warengruppe_Br√∂tchen', 'Warengruppe_Croissant', 'Warengruppe_Konditorei', 'Warengruppe_Kuchen', 'Warengruppe_Saisonbrot', 'Jahreszeit_Winter', 'Jahreszeit_Fr√ºhling', 'Jahreszeit_Sommer', 'Jahreszeit_Herbst', 'Wochentag_Nr.1', 'Wochentag_Monday', 'Wochentag_Tuesday', 'Wochentag_Wednesday', 'Wochentag_Thursday', 'Wochentag_Friday', 'Wochentag_Saturday', 'Wochentag_Sunday', 'Wettercode']\n",
      "Datenbereiche nach Wochentag:\n",
      "  Monday: 1324 Eintr√§ge\n",
      "  Tuesday: 1345 Eintr√§ge\n",
      "  Wednesday: 1342 Eintr√§ge\n",
      "  Thursday: 1334 Eintr√§ge\n",
      "  Friday: 1311 Eintr√§ge\n",
      "  Saturday: 1336 Eintr√§ge\n",
      "  Sunday: 1342 Eintr√§ge\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"üìä Naive Forecast: Umsatz vom letzten gleichen Wochentag\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Daten laden und vorbereiten\n",
    "print(\"üìã Lade Trainingsdaten...\")\n",
    "df = pd.read_csv('/workspaces/bakery_sales_prediction/5_Datasets/bakery_training_dataset.csv')\n",
    "\n",
    "# Datum konvertieren\n",
    "df['Datum'] = pd.to_datetime(df['Datum'])\n",
    "print(f\"Datensatz geladen: {len(df)} Zeilen von {df['Datum'].min()} bis {df['Datum'].max()}\")\n",
    "print(f\"Warengruppen: {sorted(df['Warengruppe_Name'].unique())}\")\n",
    "print(f\"Spalten: {list(df.columns)}\")\n",
    "\n",
    "# Wochentag hinzuf√ºgen f√ºr bessere √úbersicht\n",
    "df['Wochentag'] = df['Datum'].dt.day_name()\n",
    "print(f\"Datenbereiche nach Wochentag:\")\n",
    "for wochentag in ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']:\n",
    "    count = len(df[df['Wochentag'] == wochentag])\n",
    "    print(f\"  {wochentag}: {count} Eintr√§ge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3842a314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ID 1808011: Datum=2018-08-01, Warengruppe=Brot, Wochentag=Wednesday\n"
     ]
    }
   ],
   "source": [
    "# 2. Warengruppen-Mapping f√ºr Sample Submission\n",
    "warengruppe_mapping = {\n",
    "    1: 'Brot',\n",
    "    2: 'Br√∂tchen', \n",
    "    3: 'Croissant',\n",
    "    4: 'Konditorei',\n",
    "    5: 'Kuchen',\n",
    "    6: 'Saisonbrot'\n",
    "}\n",
    "\n",
    "def parse_sample_id(sample_id):\n",
    "    \"\"\"Parst Sample ID im Format YYMMDDW zu Datum und Warengruppe\"\"\"\n",
    "    # Konvertiere zu Integer falls Float\n",
    "    sample_int = int(float(sample_id))\n",
    "    sample_str = str(sample_int)\n",
    "    \n",
    "    if len(sample_str) != 7:\n",
    "        raise ValueError(f\"Invalid sample ID format: {sample_id}\")\n",
    "    \n",
    "    year = int('20' + sample_str[:2])\n",
    "    month = int(sample_str[2:4])\n",
    "    day = int(sample_str[4:6])\n",
    "    warengruppe_id = int(sample_str[6])\n",
    "    \n",
    "    datum = pd.to_datetime(f'{year}-{month:02d}-{day:02d}')\n",
    "    warengruppe_name = warengruppe_mapping.get(warengruppe_id, f'Unknown_{warengruppe_id}')\n",
    "    \n",
    "    return datum, warengruppe_name\n",
    "\n",
    "# Test der Parsing-Funktion\n",
    "test_id = 1808011\n",
    "test_datum, test_warengruppe = parse_sample_id(test_id)\n",
    "print(f\"Test ID {test_id}: Datum={test_datum.date()}, Warengruppe={test_warengruppe}, Wochentag={test_datum.strftime('%A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0844506d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Historische Daten: 9334 Zeilen bis 2018-07-31\n",
      "Letzte verf√ºgbare Daten: 2018-07-31\n",
      "Lookup-Dictionary erstellt mit 9334 Eintr√§gen\n",
      "Test Lookup f√ºr 2018-07-25 - Brot: 133.60‚Ç¨\n"
     ]
    }
   ],
   "source": [
    "# 3. Datensplit: Historische Daten bis 31.07.2018\n",
    "cutoff_date = pd.to_datetime('2018-07-31')\n",
    "historical_data = df[df['Datum'] <= cutoff_date].copy()\n",
    "\n",
    "print(f\"Historische Daten: {len(historical_data)} Zeilen bis {cutoff_date.date()}\")\n",
    "print(f\"Letzte verf√ºgbare Daten: {historical_data['Datum'].max().date()}\")\n",
    "\n",
    "# Erstelle Lookup-Dictionary f√ºr schnelle Suche: (Datum, Warengruppe) -> Umsatz\n",
    "umsatz_lookup = {}\n",
    "for _, row in historical_data.iterrows():\n",
    "    key = (row['Datum'].date(), row['Warengruppe_Name'])\n",
    "    umsatz_lookup[key] = row['Umsatz']\n",
    "\n",
    "print(f\"Lookup-Dictionary erstellt mit {len(umsatz_lookup)} Eintr√§gen\")\n",
    "\n",
    "# Test des Lookups\n",
    "test_date = pd.to_datetime('2018-07-25').date()  # Mittwoch vor dem 01.08.2018\n",
    "test_warengruppe = 'Brot'\n",
    "test_key = (test_date, test_warengruppe)\n",
    "if test_key in umsatz_lookup:\n",
    "    print(f\"Test Lookup f√ºr {test_date} - {test_warengruppe}: {umsatz_lookup[test_key]:.2f}‚Ç¨\")\n",
    "else:\n",
    "    print(f\"Test Lookup f√ºr {test_date} - {test_warengruppe}: Nicht gefunden\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e190642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Forecast f√ºr 2018-08-01 (Wednesday) - Brot:\n",
      "  Vorhersage: 133.60‚Ç¨\n",
      "  Referenzdatum: 2018-07-25 (1 Wochen zur√ºck)\n"
     ]
    }
   ],
   "source": [
    "# 4. Naive Vorhersage-Funktion: Gleicher Wochentag der Vorwoche\n",
    "def get_last_weekday_forecast(target_date, warengruppe_name, umsatz_lookup, max_lookback_weeks=4):\n",
    "    \"\"\"\n",
    "    Sucht den Umsatz vom gleichen Wochentag der Vorwoche.\n",
    "    Falls nicht verf√ºgbar, geht schrittweise weitere Wochen zur√ºck.\n",
    "    \"\"\"\n",
    "    for weeks_back in range(1, max_lookback_weeks + 1):\n",
    "        reference_date = (target_date - timedelta(weeks=weeks_back)).date()\n",
    "        lookup_key = (reference_date, warengruppe_name)\n",
    "        \n",
    "        if lookup_key in umsatz_lookup:\n",
    "            return umsatz_lookup[lookup_key], reference_date, weeks_back\n",
    "    \n",
    "    # Falls kein Wert gefunden wurde, gib 0 zur√ºck\n",
    "    return 0.0, None, None\n",
    "\n",
    "# Test der Vorhersage-Funktion\n",
    "test_target = pd.to_datetime('2018-08-01')  # Mittwoch\n",
    "forecast, ref_date, weeks_back = get_last_weekday_forecast(\n",
    "    test_target, 'Brot', umsatz_lookup\n",
    ")\n",
    "print(f\"Test Forecast f√ºr {test_target.date()} ({test_target.strftime('%A')}) - Brot:\")\n",
    "print(f\"  Vorhersage: {forecast:.2f}‚Ç¨\")\n",
    "print(f\"  Referenzdatum: {ref_date} ({weeks_back} Wochen zur√ºck)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7aaa3b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Lade Sample Submission...\n",
      "Sample Submission: 1830 Zeilen\n",
      "Beispiel IDs: [1808011, 1808021, 1808031, 1808041, 1808051]\n",
      "Erfolgreich geparst: 1830 IDs\n",
      "Vorhersagezeitraum: 2018-08-01 - 2019-07-30\n",
      "Warengruppen: ['Brot', 'Br√∂tchen', 'Croissant', 'Konditorei', 'Kuchen', 'Saisonbrot']\n",
      "\n",
      "Verteilung nach Wochentagen:\n",
      "  Monday: 267 Vorhersagen\n",
      "  Tuesday: 257 Vorhersagen\n",
      "  Wednesday: 237 Vorhersagen\n",
      "  Thursday: 269 Vorhersagen\n",
      "  Friday: 264 Vorhersagen\n",
      "  Saturday: 268 Vorhersagen\n",
      "  Sunday: 268 Vorhersagen\n"
     ]
    }
   ],
   "source": [
    "# 5. Sample Submission laden und verarbeiten\n",
    "print(\"üìã Lade Sample Submission...\")\n",
    "sample_submission = pd.read_csv('/workspaces/bakery_sales_prediction/5_Datasets/sample_submission.csv')\n",
    "print(f\"Sample Submission: {len(sample_submission)} Zeilen\")\n",
    "print(f\"Beispiel IDs: {sample_submission['id'].head().tolist()}\")\n",
    "\n",
    "# Parse alle Sample IDs\n",
    "parsed_data = []\n",
    "for sample_id in sample_submission['id']:\n",
    "    try:\n",
    "        datum, warengruppe_name = parse_sample_id(sample_id)\n",
    "        parsed_data.append({\n",
    "            'id': sample_id,\n",
    "            'Datum': datum,\n",
    "            'Warengruppe_Name': warengruppe_name,\n",
    "            'Wochentag': datum.strftime('%A')\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler beim Parsen von ID {sample_id}: {e}\")\n",
    "\n",
    "parsed_df = pd.DataFrame(parsed_data)\n",
    "print(f\"Erfolgreich geparst: {len(parsed_df)} IDs\")\n",
    "print(f\"Vorhersagezeitraum: {parsed_df['Datum'].min().date()} - {parsed_df['Datum'].max().date()}\")\n",
    "print(f\"Warengruppen: {sorted(parsed_df['Warengruppe_Name'].unique())}\")\n",
    "\n",
    "# Verteilung nach Wochentagen\n",
    "print(\"\\nVerteilung nach Wochentagen:\")\n",
    "wochentag_counts = parsed_df['Wochentag'].value_counts()\n",
    "for wochentag in ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']:\n",
    "    if wochentag in wochentag_counts.index:\n",
    "        print(f\"  {wochentag}: {wochentag_counts[wochentag]} Vorhersagen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fdfd0f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÆ Generiere Vorhersagen basierend auf letztem gleichen Wochentag...\n",
      "Fortschritt: 0/1830\n",
      "Fortschritt: 200/1830\n",
      "Fortschritt: 400/1830\n",
      "Fortschritt: 600/1830\n",
      "Fortschritt: 800/1830\n",
      "Fortschritt: 1000/1830\n",
      "Fortschritt: 1200/1830\n",
      "Fortschritt: 1400/1830\n",
      "Fortschritt: 1600/1830\n",
      "Fortschritt: 1800/1830\n",
      "\n",
      "Vorhersagen generiert: 1830 Zeilen\n",
      "Durchschnittlicher Umsatz: 47.16‚Ç¨\n",
      "Min/Max Umsatz: 0.00‚Ç¨ / 721.82‚Ç¨\n",
      "\n",
      "Statistiken:\n",
      "  Erfolgreiche Vorhersagen: 280\n",
      "  Fallback verwendet (>1 Woche): 245\n",
      "  Keine Daten gefunden: 1550\n",
      "  Verteilung Wochen zur√ºck: {1: 35, 2: 35, 3: 35, 4: 35, 5: 35, 6: 35, 7: 35, 8: 35}\n"
     ]
    }
   ],
   "source": [
    "# 6. Generiere Vorhersagen f√ºr alle Sample IDs\n",
    "print(\"üîÆ Generiere Vorhersagen basierend auf letztem gleichen Wochentag...\")\n",
    "\n",
    "predictions = []\n",
    "stats = {\n",
    "    'successful': 0,\n",
    "    'fallback_used': 0,\n",
    "    'no_data_found': 0,\n",
    "    'weeks_back_distribution': {}\n",
    "}\n",
    "\n",
    "for idx, row in parsed_df.iterrows():\n",
    "    if idx % 200 == 0:\n",
    "        print(f\"Fortschritt: {idx}/{len(parsed_df)}\")\n",
    "    \n",
    "    forecast, ref_date, weeks_back = get_last_weekday_forecast(\n",
    "        target_date=row['Datum'],\n",
    "        warengruppe_name=row['Warengruppe_Name'],\n",
    "        umsatz_lookup=umsatz_lookup,\n",
    "        max_lookback_weeks=8  # Erweitert auf 8 Wochen f√ºr mehr Robustheit\n",
    "    )\n",
    "    \n",
    "    predictions.append({\n",
    "        'id': row['id'],\n",
    "        'Umsatz': forecast\n",
    "    })\n",
    "    \n",
    "    # Statistiken sammeln\n",
    "    if forecast > 0:\n",
    "        stats['successful'] += 1\n",
    "        if weeks_back > 1:\n",
    "            stats['fallback_used'] += 1\n",
    "        \n",
    "        # Verteilung der Wochen zur√ºck\n",
    "        if weeks_back not in stats['weeks_back_distribution']:\n",
    "            stats['weeks_back_distribution'][weeks_back] = 0\n",
    "        stats['weeks_back_distribution'][weeks_back] += 1\n",
    "    else:\n",
    "        stats['no_data_found'] += 1\n",
    "\n",
    "# Erstelle Prediction DataFrame\n",
    "prediction_df = pd.DataFrame(predictions)\n",
    "print(f\"\\nVorhersagen generiert: {len(prediction_df)} Zeilen\")\n",
    "print(f\"Durchschnittlicher Umsatz: {prediction_df['Umsatz'].mean():.2f}‚Ç¨\")\n",
    "print(f\"Min/Max Umsatz: {prediction_df['Umsatz'].min():.2f}‚Ç¨ / {prediction_df['Umsatz'].max():.2f}‚Ç¨\")\n",
    "\n",
    "print(f\"\\nStatistiken:\")\n",
    "print(f\"  Erfolgreiche Vorhersagen: {stats['successful']}\")\n",
    "print(f\"  Fallback verwendet (>1 Woche): {stats['fallback_used']}\")\n",
    "print(f\"  Keine Daten gefunden: {stats['no_data_found']}\")\n",
    "print(f\"  Verteilung Wochen zur√ºck: {stats['weeks_back_distribution']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f315f78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Speichere finale Vorhersagen...\n",
      "‚úÖ Vorhersagen gespeichert: /workspaces/bakery_sales_prediction/2_BaselineModel/prediction.csv\n",
      "Anzahl Zeilen: 1830\n",
      "Spalten: ['id', 'Umsatz']\n",
      "\n",
      "Erste 10 Vorhersagen:\n",
      "ID 1808011: 2018-08-01 (Wednesday) - Brot - 133.60‚Ç¨\n",
      "ID 1808021: 2018-08-02 (Thursday) - Brot - 202.54‚Ç¨\n",
      "ID 1808031: 2018-08-03 (Friday) - Brot - 198.23‚Ç¨\n",
      "ID 1808041: 2018-08-04 (Saturday) - Brot - 214.47‚Ç¨\n",
      "ID 1808051: 2018-08-05 (Sunday) - Brot - 129.80‚Ç¨\n",
      "ID 1808061: 2018-08-06 (Monday) - Brot - 148.54‚Ç¨\n",
      "ID 1808071: 2018-08-07 (Tuesday) - Brot - 123.08‚Ç¨\n",
      "ID 1808081: 2018-08-08 (Wednesday) - Brot - 133.60‚Ç¨\n",
      "ID 1808091: 2018-08-09 (Thursday) - Brot - 202.54‚Ç¨\n",
      "ID 1808101: 2018-08-10 (Friday) - Brot - 198.23‚Ç¨\n"
     ]
    }
   ],
   "source": [
    "# 7. Speichere finale Vorhersagen\n",
    "print(\"üíæ Speichere finale Vorhersagen...\")\n",
    "\n",
    "# Stelle sicher, dass Reihenfolge identisch zur Sample Submission ist\n",
    "final_predictions = sample_submission[['id']].merge(prediction_df, on='id', how='left')\n",
    "\n",
    "# Pr√ºfe auf fehlende Vorhersagen\n",
    "missing_predictions = final_predictions['Umsatz'].isna().sum()\n",
    "if missing_predictions > 0:\n",
    "    print(f\"‚ö†Ô∏è Warnung: {missing_predictions} fehlende Vorhersagen gefunden!\")\n",
    "    final_predictions['Umsatz'].fillna(0, inplace=True)\n",
    "\n",
    "# Speichere CSV\n",
    "output_path = '/workspaces/bakery_sales_prediction/2_BaselineModel/prediction_naive_forecasting_baseline.csv'\n",
    "final_predictions.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ Vorhersagen gespeichert: {output_path}\")\n",
    "print(f\"Anzahl Zeilen: {len(final_predictions)}\")\n",
    "print(f\"Spalten: {list(final_predictions.columns)}\")\n",
    "\n",
    "# Zeige erste Vorhersagen\n",
    "print(\"\\nErste 10 Vorhersagen:\")\n",
    "display_df = final_predictions.head(10).copy()\n",
    "for idx, row in display_df.iterrows():\n",
    "    try:\n",
    "        datum, warengruppe = parse_sample_id(row['id'])\n",
    "        wochentag = datum.strftime('%A')\n",
    "        print(f\"ID {int(row['id'])}: {datum.date()} ({wochentag}) - {warengruppe} - {row['Umsatz']:.2f}‚Ç¨\")\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler bei ID {row['id']}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10cc9f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà Detaillierte Analyse der Vorhersagen:\n",
      "============================================================\n",
      "Vorhersagen pro Warengruppe:\n",
      "                  count    mean     std  min     max\n",
      "Warengruppe_Name                                    \n",
      "Brot                355   25.92   61.69  0.0  214.47\n",
      "Br√∂tchen            355  103.62  240.52  0.0  721.82\n",
      "Croissant           355   55.23  128.87  0.0  433.82\n",
      "Konditorei          354   11.78   28.74  0.0  128.95\n",
      "Kuchen              355   46.58  108.70  0.0  335.82\n",
      "Saisonbrot           56    0.00    0.00  0.0    0.00\n",
      "\n",
      "Vorhersagen pro Wochentag:\n",
      "           count   mean     std  min     max\n",
      "Wochentag                                   \n",
      "Monday       267  45.26  130.47  0.0  616.36\n",
      "Tuesday      257  40.89  119.66  0.0  586.08\n",
      "Wednesday    237  48.17  136.09  0.0  651.75\n",
      "Thursday     269  46.59  132.64  0.0  628.29\n",
      "Friday       264  47.66  138.17  0.0  677.42\n",
      "Saturday     268  49.16  145.22  0.0  716.58\n",
      "Sunday       268  52.25  151.30  0.0  721.82\n",
      "\n",
      "‚ö†Ô∏è Null-Vorhersagen: 1550 von 1830\n",
      "Null-Vorhersagen pro Warengruppe:\n",
      "  Brot: 299\n",
      "  Br√∂tchen: 299\n",
      "  Croissant: 299\n",
      "  Konditorei: 298\n",
      "  Kuchen: 299\n",
      "  Saisonbrot: 56\n",
      "\n",
      "Modell-Zusammenfassung:\n",
      "Modell: Naive Forecast - Gleicher Wochentag der Vorwoche\n",
      "Historischer Datenzeitraum: 2013-07-01 - 2018-07-31\n",
      "Vorhersagezeitraum: 2018-08-01 - 2019-07-30\n",
      "Anzahl Vorhersagen: 1830\n",
      "Erfolgsrate: 15.3%\n",
      "Durchschnittlicher vorhergesagter Umsatz: 47.16‚Ç¨\n"
     ]
    }
   ],
   "source": [
    "# 8. Detaillierte Analyse der Vorhersagen\n",
    "print(\"üìà Detaillierte Analyse der Vorhersagen:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Analyse pro Warengruppe\n",
    "warengruppe_analysis = parsed_df.merge(prediction_df, on='id')\n",
    "warengruppe_stats = warengruppe_analysis.groupby('Warengruppe_Name')['Umsatz'].agg([\n",
    "    'count', 'mean', 'std', 'min', 'max'\n",
    "]).round(2)\n",
    "\n",
    "print(\"Vorhersagen pro Warengruppe:\")\n",
    "print(warengruppe_stats)\n",
    "\n",
    "# Analyse pro Wochentag\n",
    "print(\"\\nVorhersagen pro Wochentag:\")\n",
    "wochentag_stats = warengruppe_analysis.groupby('Wochentag')['Umsatz'].agg([\n",
    "    'count', 'mean', 'std', 'min', 'max'\n",
    "]).round(2)\n",
    "# Sortiere nach Wochentag-Reihenfolge\n",
    "wochentag_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "wochentag_stats = wochentag_stats.reindex([day for day in wochentag_order if day in wochentag_stats.index])\n",
    "print(wochentag_stats)\n",
    "\n",
    "# Analyse der Null-Vorhersagen\n",
    "null_predictions = warengruppe_analysis[warengruppe_analysis['Umsatz'] == 0]\n",
    "if len(null_predictions) > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è Null-Vorhersagen: {len(null_predictions)} von {len(warengruppe_analysis)}\")\n",
    "    null_by_warengruppe = null_predictions.groupby('Warengruppe_Name').size()\n",
    "    print(\"Null-Vorhersagen pro Warengruppe:\")\n",
    "    for warengruppe, count in null_by_warengruppe.items():\n",
    "        print(f\"  {warengruppe}: {count}\")\n",
    "\n",
    "print(f\"\\nModell-Zusammenfassung:\")\n",
    "print(f\"Modell: Naive Forecast - Gleicher Wochentag der Vorwoche\")\n",
    "print(f\"Historischer Datenzeitraum: {historical_data['Datum'].min().date()} - {historical_data['Datum'].max().date()}\")\n",
    "print(f\"Vorhersagezeitraum: {parsed_df['Datum'].min().date()} - {parsed_df['Datum'].max().date()}\")\n",
    "print(f\"Anzahl Vorhersagen: {len(final_predictions)}\")\n",
    "print(f\"Erfolgsrate: {(stats['successful']/len(parsed_df)*100):.1f}%\")\n",
    "print(f\"Durchschnittlicher vorhergesagter Umsatz: {final_predictions['Umsatz'].mean():.2f}‚Ç¨\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3286aa63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Validierung des Modells...\n",
      "Validierungsdaten: 155 Eintr√§ge im Juli 2018\n",
      "Validierungs-Lookup: 9179 historische Eintr√§ge bis Juni 2018\n",
      "\n",
      "Validierungs-Metriken (Juli 2018):\n",
      "MAE: 78.70‚Ç¨\n",
      "RMSE: 107.22‚Ç¨\n",
      "R¬≤: 0.6497\n",
      "Anzahl Validierungsvorhersagen: 155\n",
      "Durchschnittlicher tats√§chlicher Umsatz: 284.88‚Ç¨\n",
      "Durchschnittlicher vorhergesagter Umsatz: 223.24‚Ç¨\n"
     ]
    }
   ],
   "source": [
    "# 9. Validierung: Teste das Modell auf einem bekannten Zeitraum\n",
    "print(\"üìä Validierung des Modells...\")\n",
    "\n",
    "# Verwende Juli 2018 als Validierungsmonat (noch in historischen Daten enthalten)\n",
    "val_start = pd.to_datetime('2018-07-01')\n",
    "val_end = pd.to_datetime('2018-07-31')\n",
    "\n",
    "# Erstelle Validierungsdaten\n",
    "val_data = historical_data[\n",
    "    (historical_data['Datum'] >= val_start) & \n",
    "    (historical_data['Datum'] <= val_end)\n",
    "].copy()\n",
    "\n",
    "# Erstelle historische Daten nur bis Juni 2018 f√ºr Validierung\n",
    "val_historical = historical_data[historical_data['Datum'] < val_start].copy()\n",
    "val_umsatz_lookup = {}\n",
    "for _, row in val_historical.iterrows():\n",
    "    key = (row['Datum'].date(), row['Warengruppe_Name'])\n",
    "    val_umsatz_lookup[key] = row['Umsatz']\n",
    "\n",
    "print(f\"Validierungsdaten: {len(val_data)} Eintr√§ge im Juli 2018\")\n",
    "print(f\"Validierungs-Lookup: {len(val_umsatz_lookup)} historische Eintr√§ge bis Juni 2018\")\n",
    "\n",
    "# Generiere Vorhersagen f√ºr Validierungsmonat\n",
    "val_predictions = []\n",
    "val_actuals = []\n",
    "\n",
    "for _, row in val_data.iterrows():\n",
    "    # Vorhersage mit gleichem Modell\n",
    "    forecast, _, _ = get_last_weekday_forecast(\n",
    "        target_date=row['Datum'],\n",
    "        warengruppe_name=row['Warengruppe_Name'],\n",
    "        umsatz_lookup=val_umsatz_lookup,\n",
    "        max_lookback_weeks=8\n",
    "    )\n",
    "    \n",
    "    val_predictions.append(forecast)\n",
    "    val_actuals.append(row['Umsatz'])\n",
    "\n",
    "val_predictions = np.array(val_predictions)\n",
    "val_actuals = np.array(val_actuals)\n",
    "\n",
    "# Berechne Validierungsmetriken\n",
    "mae = np.mean(np.abs(val_predictions - val_actuals))\n",
    "mse = np.mean((val_predictions - val_actuals) ** 2)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# R¬≤\n",
    "ss_res = np.sum((val_actuals - val_predictions) ** 2)\n",
    "ss_tot = np.sum((val_actuals - np.mean(val_actuals)) ** 2)\n",
    "r2 = 1 - (ss_res / ss_tot)\n",
    "\n",
    "print(f\"\\nValidierungs-Metriken (Juli 2018):\")\n",
    "print(f\"MAE: {mae:.2f}‚Ç¨\")\n",
    "print(f\"RMSE: {rmse:.2f}‚Ç¨\")\n",
    "print(f\"R¬≤: {r2:.4f}\")\n",
    "print(f\"Anzahl Validierungsvorhersagen: {len(val_predictions)}\")\n",
    "print(f\"Durchschnittlicher tats√§chlicher Umsatz: {val_actuals.mean():.2f}‚Ç¨\")\n",
    "print(f\"Durchschnittlicher vorhergesagter Umsatz: {val_predictions.mean():.2f}‚Ç¨\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
